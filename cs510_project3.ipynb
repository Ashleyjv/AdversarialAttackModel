{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "# CS 510 Project 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZSlp3DAjdYf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# Part 0: train your own MNIST model (do not modify code in this part!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJNruuoIODV1"
      },
      "source": [
        "The following training code is mainly based on [TensorFlow 2 quickstart for experts](https://www.tensorflow.org/tutorials/quickstart/advanced). The goal of this part is to familiarize yourself with basic usage of Colab notebook and TensorFlow. In this part, you only need to learn and run the code. By the end of this part, you will get a neural network which can classifiy the handwritten data with ~98% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOsVdx6GGHmU"
      },
      "source": [
        "Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7DDTiZGRTo"
      },
      "source": [
        "Import TensorFlow into your program:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVgI_FhvAzvu"
      },
      "outputs": [],
      "source": [
        "# you can skip this if you use Google colab\n",
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt3JKZEd0ZPc"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OQ98Ukpen0c"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "tf.keras.utils.set_random_seed(0)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqFRS6K07jJs"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Evqx0S22r_"
      },
      "source": [
        "Use `tf.data` to batch and shuffle the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iu_quO024c2"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QfL9lq9EN7Q"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuhRTiMDNWFL"
      },
      "source": [
        "Show some training images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k3mQFERNRhX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow((images[i]*255).numpy().astype(\"uint8\").reshape(28, 28), cmap='gray', vmin=0, vmax=255)\n",
        "    plt.title(labels[i].numpy())\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "outputs": [],
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(100, activation='relu')\n",
        "    self.d2 = Dense(20, activation='relu')\n",
        "    self.final = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.d2(x)\n",
        "    return self.final(x)\n",
        "\n",
        "  def get_internal_activations(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x_d1 = self.d1(x)\n",
        "    x_d2 = self.d2(x_d1)\n",
        "    return x_d1, x_d2\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "Choose an optimizer and loss function for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def loss_object(target, pred):\n",
        "  target = tf.one_hot(target, 10)\n",
        "  pred_conf = tf.nn.softmax(pred)\n",
        "  cross_entropy = -tf.reduce_sum(target * tf.math.log(pred_conf))\n",
        "  return cross_entropy\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0MqHFb4F_qn"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Use `tf.GradientTape` to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZACiVqA8KQV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "Test the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIKdEzHAJGt7"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-2pkctU_Ci7"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )\n",
        "\n",
        "  if test_accuracy.result() > .95:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~95% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ngj9KmNpAQ"
      },
      "source": [
        "\n",
        "# Part 1: Targeted Adversarial Attacks (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDHpd-axPL_s"
      },
      "source": [
        "In this part, you need to find adversarial images that:\n",
        "\n",
        "   - purturbed from imaged that are labeled 5 and MyModel() predicts 5\n",
        "\n",
        "   - MyModel(), after purturbation, predicts 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJxP_iV3isz6"
      },
      "source": [
        "We will start with base images (from ground truth label 5)\n",
        "Specifically, you should implement make_noise_pattern() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPX4T0XJsxt2"
      },
      "outputs": [],
      "source": [
        "# These are example parameters (they worked with my code)... you can modify those if you want\n",
        "EPSILON = .01\n",
        "EPOCHS  = 10\n",
        "BATCH   = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfT9C3nZyYK7"
      },
      "outputs": [],
      "source": [
        "# These must not be changed\n",
        "ORIGINAL_LABEL = 5\n",
        "TARGET_LABEL   = 0\n",
        "\n",
        "NUM_SAMPLES    = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmLs2PXOiEnr"
      },
      "outputs": [],
      "source": [
        "# Write this function. This should sign values of gradient\n",
        "# useful methods\n",
        "#   1. tape.gradient( xxx, xxx )\n",
        "#   2. tf.sign()\n",
        "#\n",
        "#\n",
        "# please refer to https://www.tensorflow.org/tutorials/generative/adversarial_fgsm and see create_adversarial_pattern() function.\n",
        "#\n",
        "\n",
        "def make_noise_pattern(x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Write your code here\n",
        "\n",
        "  return tf.sign(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYya-iB-zASb"
      },
      "outputs": [],
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "adv_samples = tf.reshape((), (0, 28, 28, 1))\n",
        "orig_samples = tf.reshape((), (0, 28, 28, 1))\n",
        "\n",
        "for i in range(0, x_test.shape[0], BATCH):\n",
        "  x_samples = tf.Variable(x_test[y_test == ORIGINAL_LABEL][(i):(i+BATCH)])\n",
        "\n",
        "  perturbed = x_samples + EPSILON * make_noise_pattern(x_samples)\n",
        "  perturbed = tf.clip_by_value(perturbed, 0, 1.)\n",
        "\n",
        "  for _ in range(EPOCHS):\n",
        "    perturbed += EPSILON * make_noise_pattern(perturbed)\n",
        "    perturbed = tf.clip_by_value(perturbed, 0, 1.)\n",
        "\n",
        "  sample_succ = tf.boolean_mask(perturbed,  (TARGET_LABEL   == tf.math.argmax(model(perturbed), axis=1)) & \\\n",
        "                                            (ORIGINAL_LABEL == tf.math.argmax(model(x_samples), axis=1)))\n",
        "\n",
        "  orig_succ   = tf.boolean_mask(x_samples,  (TARGET_LABEL   == tf.math.argmax(model(perturbed), axis=1)) & \\\n",
        "                                            (ORIGINAL_LABEL == tf.math.argmax(model(x_samples), axis=1)))\n",
        "\n",
        "  print (f'perturbing images:{i}~{i+BATCH}, found {len(sample_succ)} samples')\n",
        "\n",
        "  adv_samples = tf.concat([adv_samples, sample_succ], 0)\n",
        "  orig_samples = tf.concat([orig_samples, orig_succ], 0)\n",
        "\n",
        "  if (NUM_SAMPLES <= len(adv_samples)):\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE4ER-fe4F1o"
      },
      "source": [
        "# **Task 1**: Below number should be more than or equals to 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDqSE82G3dBM"
      },
      "outputs": [],
      "source": [
        "len(adv_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIsid_hD4Ya3"
      },
      "source": [
        "# **Task 2**: Below images need to obviously look like 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNA82_oIwD_Y"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 80))\n",
        "\n",
        "for i in range(200):\n",
        "  ax = plt.subplot(40, 5, i + 1)\n",
        "  plt.imshow((adv_samples[i]*255).numpy().astype(\"uint8\").reshape(28, 28), cmap='gray', vmin=0, vmax=255)\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw0n_lCZX8Fc"
      },
      "source": [
        "# Part 2: Attack Detection (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMGSst2abEk"
      },
      "source": [
        "This part is to detect attacks.\n",
        "\n",
        "First, observe images or internal cell values (adversarial samples vs original images).\n",
        "\n",
        "For example, you may observe that some neurons show diffrent values with adversarial samples. Then you can use these values to compose a simple classifier.\n",
        "\n",
        "And then, propose a method to detect them.\n",
        "\n",
        "It does not have to be the state-of-art. Comparative evaluations are not needed.\n",
        "\n",
        "Below part, the given code will bring 200 adversarial images and 200 normal images.\n",
        "\n",
        "You should use first 100 images for an observation or any kind of training (if needed). And then you should use the later 100 images to test your methodology.\n",
        "\n",
        "\n",
        "Here, we aim at 80% of f-1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYX8A8i8dUv8"
      },
      "source": [
        "# **Task 3**: propose your detection method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9IGHcO6eIbR"
      },
      "source": [
        "Answer for Task 3: Show your observations below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGptGoNT6j9K"
      },
      "outputs": [],
      "source": [
        "x_samples = tf.Variable(x_test[y_test == TARGET_LABEL][:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9DdqH-p-PyT"
      },
      "outputs": [],
      "source": [
        "# Data for observations, don't go out of the boundary.\n",
        "adv_samples[:100]\n",
        "x_samples[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y_w-tYDxpSn"
      },
      "outputs": [],
      "source": [
        "# You may want to use internal values of model (optional)\n",
        "d1_adv, d2_adv = model.get_internal_activations(adv_samples[:100])\n",
        "d1_noarmal, d2_noarmal = model.get_internal_activations(x_samples[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UALGDq_WzpH0"
      },
      "source": [
        "Answer for Task 3: Here, propose your detection method here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtCrIkhg-Sy1"
      },
      "outputs": [],
      "source": [
        "# Data for a test.\n",
        "adv_samples_test = adv_samples[100:200]\n",
        "normal_samples_test = x_samples[100:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K80m-sYIHWDC"
      },
      "outputs": [],
      "source": [
        "# Implement your detection method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2Au2vVmdf54"
      },
      "source": [
        "# **Task 4**: Print your precision, recall, f1 score. F1 score should be higher than 80%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Icm9_rbK0BAb",
        "outputId": "fb3c44c5-7e92-4251-fde1-4106d4853f0d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntp = \\nfn =\\ntn = \\nfp =\\n'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "tp =\n",
        "fn =\n",
        "tn =\n",
        "fp =\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51PwtcLRsETZ"
      },
      "outputs": [],
      "source": [
        "pr = tp / (tp + fp)\n",
        "rc = tp / (tp + fn)\n",
        "\n",
        "print ('precision:', pr, 'recall:', rc, 'f-1', 2 * pr * rc / (pr + rc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0U-MOadeBzq"
      },
      "source": [
        "# **Task 5**: Tell your feeling about the different asepct of this project against the traditional software analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8976CEDzeDH8"
      },
      "source": [
        "Answer for Task 5:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "20e40d8fc09a6690434ad602c7eb2d8de15d36ec466bfbfb0de97c7c540d7363"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
